{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from time import sleep\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "doc = []\n",
    "with open('dates.txt') as file:\n",
    "    for line in file:\n",
    "        doc.append(line)\n",
    "\n",
    "medical_dates_df = pd.Series(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment, you'll be working with messy medical data and using regex to extract relevant infromation from the data.\n",
    "\n",
    "Each line of the `dates.txt` file corresponds to a medical note. Each note has a date that needs to be extracted, but each date is encoded in one of many formats.\n",
    "\n",
    "The goal of this assignment is to correctly identify all of the different date variants encoded in this dataset and to properly normalize and sort the dates.\n",
    "\n",
    "Here is a list of some of the variants you might encounter in this dataset:\n",
    "* 04/20/2009; 04/20/09; 4/20/09; 4/3/09\n",
    "* Mar-20-2009; Mar 20, 2009; March 20, 2009;  Mar. 20, 2009; Mar 20 2009;\n",
    "* 20 Mar 2009; 20 March 2009; 20 Mar. 2009; 20 March, 2009\n",
    "* Mar 20th, 2009; Mar 21st, 2009; Mar 22nd, 2009\n",
    "* Feb 2009; Sep 2009; Oct 2010\n",
    "* 6/2008; 12/2009\n",
    "* 2009; 2010\n",
    "\n",
    "Once you have extracted these date patterns from the text, the next step is to sort them in ascending chronological order accoring to the following rules:\n",
    "* Assume all dates in xx/xx/xx format are mm/dd/yy\n",
    "* Assume all dates where year is encoded in only two digits are years from the 1900's (e.g. 1/5/89 is January 5th, 1989)\n",
    "* If the day is missing (e.g. 9/2009), assume it is the first day of the month (e.g. September 1, 2009).\n",
    "* If the month is missing (e.g. 2010), assume it is the first of January of that year (e.g. January 1, 2010).\n",
    "* Watch out for potential typos as this is a raw, real-life derived dataset.\n",
    "\n",
    "With these rules in mind, find the correct date in each note and return a pandas Series in chronological order of the original Series' indices.\n",
    "\n",
    "For example if the original series was this:\n",
    "\n",
    "    0    1999\n",
    "    1    2010\n",
    "    2    1978\n",
    "    3    2015\n",
    "    4    1985\n",
    "\n",
    "Your function should return this:\n",
    "\n",
    "    0    2\n",
    "    1    4\n",
    "    2    0\n",
    "    3    1\n",
    "    4    3\n",
    "\n",
    "Your score will be calculated using [Kendall's tau](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient), a correlation measure for ordinal data.\n",
    "\n",
    "*This function should return a Series of length 500 and dtype int.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "import re\n",
    "import typing\n",
    "from functools import lru_cache\n",
    "from string import digits\n",
    "from typing import Pattern\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from text_mining_package.nic_date_date_class import NicDate\n",
    "\n",
    "\n",
    "class DateFinder:\n",
    "    \"\"\"\n",
    "    Date Finder is the main class used to find a date in supported format in the line of text.\n",
    "    :arg: str containing a date in the supported format\n",
    "    \"\"\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        :return: Date in american mm/dd/yyyy format (all numeric)\n",
    "        \"\"\"\n",
    "        return f\"{self.month}/{self.day}/{self.year}\"\n",
    "\n",
    "    def __init__(self, raw_string: str = str()):\n",
    "        date_regexes_tuple = self.create_date_regex()\n",
    "        nic_date_result = self.find_dates(date_regex_tuples=date_regexes_tuple, raw_string=raw_string)\n",
    "        self.month = self.month_process_date(nic_date_result)\n",
    "        self.day = self.day_process_date(nic_date_result)\n",
    "        self.year = self.year_process_date(nic_date_result)\n",
    "        self.python_date = self.convert_to_python_datetime()\n",
    "\n",
    "    @lru_cache(maxsize=2)\n",
    "    def find_dates(self, date_regex_tuples: tuple[Pattern[str], ...] = None, raw_string: str = str()) -> NicDate:\n",
    "        \"\"\"\n",
    "        This function applies the regex to a given raw string to extract the dates results.\n",
    "        :param date_regex_tuples: A list of compiled regex functions to test against the string.\n",
    "        :param raw_string: A string in which to find a date pattern.\n",
    "        :return: NicDate Object - with Month, Day and Year\n",
    "        :rtype: NicDate\n",
    "        \"\"\"\n",
    "\n",
    "        # This section pre-processes the string to make it more compatible with regex, removing anything that's not\n",
    "        # a word character or a space\n",
    "        raw_string = re.sub(r'^[^0-9a-zA-Z\\\\\\-]', '', raw_string)\n",
    "\n",
    "        # Since none of the dates are period delimited, we can remove periods and commas too.\n",
    "        raw_string = re.sub(r'[\\.,]', '', raw_string)\n",
    "\n",
    "        ##########################################################################################################\n",
    "        # List comprehension is used because it's the fastest way to iterate in Python\n",
    "        # Loop through all regexes, perform a search, and find the hit by filtering out the Nones to get the match\n",
    "        # object.Note I don't use an IF condition above because checking would require that the regex be run twice,\n",
    "        # slowing things down.\n",
    "        ###########################################################################################################\n",
    "        search_results = [tuple(re.finditer(pattern=date_regex_tuple, string=raw_string)) for date_regex_tuple in\n",
    "                          date_regex_tuples]\n",
    "        search_results = list(itertools.chain.from_iterable([x for x in search_results if x]))\n",
    "\n",
    "        if len(search_results) == 0:\n",
    "            print(f\"No date found in {raw_string}\")\n",
    "            raise ValueError\n",
    "        # Dev code to check assumption that only one regex expression will match. Possible remove in production\n",
    "        # for efficiency.\n",
    "\n",
    "        # This is here because the regex patterns captured some junk as well as valid info. Example 'May 14,\n",
    "        # 1989 QTc  467 ms  Pertinent Medical Review of Systems Constitutional: the QTc 476 Note the day default is\n",
    "        # not None, but is one to fulfill the requirement September 1985 appear as September 1, 1985\n",
    "        if len(search_results) > 1:\n",
    "\n",
    "            # This is being added to handle the problem of multiple hits from regex.  First solution is to\n",
    "            # assume the first match is best.\n",
    "            search_results_collector = list()\n",
    "            for search_result in search_results:\n",
    "                # Generate the valid results.\n",
    "                try:\n",
    "                    dates_result = NicDate(month=search_result.groupdict().get('month', '1'),\n",
    "                                           date=search_result.groupdict().get('day', '1'),\n",
    "                                           year=search_result.groupdict().get('year', None))\n",
    "\n",
    "                    self.month = self.month_process_date(dates_result)\n",
    "                    self.day = self.day_process_date(dates_result)\n",
    "                    self.year = self.year_process_date(dates_result)\n",
    "                    search_results_collector.append(dates_result)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "            dates_result = search_results_collector.pop(0)\n",
    "\n",
    "        elif len(search_results) == 1:\n",
    "            search_result = search_results.pop()\n",
    "            dates_result = NicDate(month=search_result.groupdict().get('month', '1'),\n",
    "                                   date=search_result.groupdict().get('day', '1'),\n",
    "                                   year=search_result.groupdict().get('year', None))\n",
    "\n",
    "        return dates_result\n",
    "\n",
    "    @lru_cache(maxsize=2)\n",
    "    def create_date_regex(self) -> tuple[Pattern[str], ...]:\n",
    "        \"\"\"\n",
    "        This function creates a complex regex pattern by concatenating strings and then compiling.\n",
    "        It is wrapped in a @lru_cache so the code only has to be run once per instance.\n",
    "        Named groups are used to set up dictionaries in groupdict() so results can be addressed by a common structure.\n",
    "\n",
    "        :return: re.Pattern - regex pattern to find dates.\n",
    "        \"\"\"\n",
    "        # Keeping the compilation in a separate function helps keep code clean and readable\n",
    "        # In order to use repeated names we have to compile each separately.\n",
    "        regex_string_tuples = (r'(?P<mmddyyyy>(?P<month>\\d{1,2})[\\-/](?P<day>\\d{1,2})[\\-/](?P<year>\\d{1,4}))',\n",
    "                               r'(?P<ddmmmyyyy>(?P<day>\\d{1,2})\\s+(?P<month>\\w{3,})\\s+(?P<year>[\\d{2}|\\d{4}]\\s))',\n",
    "                               r'(?P<ddmmmyy>(?P<month>\\w{3,})\\s+(?P<day>\\d{1,2})[,\\s]+(?P<year>\\d{2}\\s))',\n",
    "                               r'(?P<ddmmmyyyy>(?P<month>\\w{3,})\\s+(?P<day>\\d{1,2})[,\\s]+(?P<year>\\d{4}))',\n",
    "                               r'(?P<month>\\w{3,})[,\\s]+(?P<year>\\d{4})', r'(?P<month>\\d{1,2})[\\/]+(?P<year>\\d{4})',\n",
    "                               r'\\s\\D(?P<year>\\d{4})[\\D\\w\\s]', r'\\D+\\s.(?P<year>\\d{4})$',\n",
    "                               r'(?:\\D+\\s)(?P<year>\\d{4})(?:[\\D\\s]+)', r'^(?P<year>\\d{4})(?:[\\D\\s+])',\n",
    "                               r'(?:[\\D+\\s])(?P<year>\\d{4})(?:[\\D\\s])')\n",
    "\n",
    "        # This additional code was added in to handle the case of a 3 letter month with a stray typo e.g. pOct\n",
    "        # IT may seem like overfitting, but at this point the best solution I could come up with was to regex the\n",
    "        # months with an extra value before or after. Fortunately we have the month names (short & Long)  in the month\n",
    "        # conversion dict.\n",
    "        month_regex_strings = [fr'(?P<month_{month}>[\\w\\s]{month})[\\w\\s](?P<year>\\d{4})' for month in\n",
    "                               self.create_month_conversion_dict().keys()]\n",
    "        regex_string_tuples = tuple(itertools.chain(*(regex_string_tuples, month_regex_strings)))\n",
    "\n",
    "        # Note -Tuples use less memory. If mutation is not needed, tuples are used herein\n",
    "        compiled_regex_tuple = tuple(\n",
    "            [re.compile(pattern=regex_string_tuple, flags=re.IGNORECASE) for regex_string_tuple in regex_string_tuples])\n",
    "        return compiled_regex_tuple\n",
    "\n",
    "    @lru_cache(maxsize=2)\n",
    "    def create_month_conversion_dict(self) -> dict:\n",
    "        \"\"\"\n",
    "        The purpose of this function is to create a dictionary where keys are text which can represent a month, and the\n",
    "        numbers are the sequence of the month from 1-12\n",
    "\n",
    "        :return: dictionary where the keys are the short names of the month, and the values are the numerical sequence of the month.\n",
    "        \"\"\"\n",
    "\n",
    "        ######################\n",
    "        # Create Short Months\n",
    "        ######################\n",
    "        month_names_short = ('jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec')\n",
    "        # Array is written as numbers 1-12 rather than generated because previous testing has shown direct read to be\n",
    "        # faster\n",
    "        month_numbers = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype=np.uint8)\n",
    "        month_conversion_dict = {a: b for a, b in zip(month_names_short, month_numbers)}\n",
    "\n",
    "        ######################\n",
    "        # Create Long Months\n",
    "        ######################\n",
    "        month_names_long = (\n",
    "            'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october',\n",
    "            'november', 'december', 'jan')\n",
    "        month_conversion_dict.update({a: b for a, b in zip(month_names_long, month_numbers)})\n",
    "\n",
    "        return month_conversion_dict\n",
    "\n",
    "    @lru_cache(maxsize=2)\n",
    "    def day_process_date(self, search_result: NicDate) -> np.uint8:\n",
    "        \"\"\"\n",
    "        The purpose of this function is to process the date part of the NicDate object. It verifies that it's a valid date.\n",
    "        Validation includes greater than 0, and less than 29, 30, or 31 depending on the Month.\n",
    "\n",
    "        :param search_result: Object of NicDate type from which to process the date.\n",
    "        :return: The day number of the month, validated to make sure it's a valid date. (e.g.) No Feb 31st, June 33rd.\n",
    "        \"\"\"\n",
    "\n",
    "        # None is an acceptable value because the requirements state that September 1, 1985 should be handled as 1\n",
    "        # set value to string of one and handle normally\n",
    "        if search_result.date is None:\n",
    "            return np.uint8(1)\n",
    "\n",
    "        if search_result.date.isdigit():\n",
    "            day_as_num = np.uint8(search_result.date)\n",
    "            this_month_max_date = NicDate.find_largest_day(result_month=self.month_process_date(search_result))\n",
    "            if any((day_as_num < 0, day_as_num > this_month_max_date)):\n",
    "                raise ValueError(\"Not a valid Date\")\n",
    "            return day_as_num\n",
    "        else:\n",
    "            raise ValueError(\"Non digit found in day\")\n",
    "\n",
    "    @lru_cache(maxsize=2)\n",
    "    def month_process_date(self, search_result: NicDate) -> typing.Union[None, np.uint8]:\n",
    "        \"\"\"\n",
    "\n",
    "        :param search_result: NicDate - DAte in Nicdate format\n",
    "        :return: sequential number of the month.\n",
    "        \"\"\"\n",
    "        month = search_result.month\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        # Handle the simple case where the month comes back as a digit. Validate that its between 1 and 12.\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        if month is None:\n",
    "            return np.uint8(1)\n",
    "\n",
    "        if month.isdigit():\n",
    "            month_as_num = np.uint8(month)\n",
    "            if any((month_as_num < 0, month_as_num > 12)):\n",
    "                raise ValueError(f\"Bad Month info {month_as_num}\")\n",
    "            return month_as_num\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        # Since we allow typos in to the month, we have to handle them here. The first case handles a proper month\n",
    "        # which is not a typo. IF there is a typo we search all the months (which are the keys of the month convers\n",
    "        # ion dictionary.\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        elif month.isalpha():\n",
    "            mcd = self.create_month_conversion_dict()\n",
    "            mcd_keys = tuple(mcd.keys())\n",
    "            # The nice simple case.\n",
    "            if month in mcd_keys:\n",
    "                month_as_num = mcd.get(month.lower(), np.nan)\n",
    "            # The complicated Case.\n",
    "            else:\n",
    "                month_searcher_regex_string = \"|\".join([fr\"{clean_month}\" for clean_month in mcd_keys])\n",
    "                month_search_regex = re.compile(month_searcher_regex_string, re.IGNORECASE)\n",
    "                month_search_result = re.search(pattern=month_search_regex, string=month)\n",
    "                if month_search_result is None:\n",
    "                    month_as_num = np.nan\n",
    "                else:\n",
    "                    clean_month = month_search_result.group(0)\n",
    "                    month_as_num = mcd.get(clean_month.lower(), np.nan)\n",
    "            # Handle the case where the dictionary doesn't work.\n",
    "            if month_as_num is np.nan:\n",
    "                month_as_num = np.uint8(1)\n",
    "            return month_as_num\n",
    "        elif month.isalnum():\n",
    "            search_result.month = search_result.month.strip(digits)\n",
    "            new_search_result_month = self.month_process_date(search_result=search_result)\n",
    "            return new_search_result_month\n",
    "\n",
    "    def year_process_date(self, nic_date_result: NicDate) -> np.uint16:\n",
    "        \"\"\"\n",
    "        The purpose of this function is to process the year in a NicDate object.\n",
    "        Two digit years are assumed to be the 20th century (19XX). Four digit years are passed through. Anything other\n",
    "        than a two or four digit year will fail.\n",
    "\n",
    "        :param nic_date_result: NicDate object from which to extract the year\n",
    "        :type nic_date_result: NicDate\n",
    "        :return: YYYY four digit representation of the year.\n",
    "        \"\"\"\n",
    "\n",
    "        #####################################################\n",
    "        # Handle 2 year case with assumption of 20th century\n",
    "        #####################################################\n",
    "        if len(nic_date_result.year) == 2:\n",
    "            year_number = np.uint16(f\"19{nic_date_result.year}\")\n",
    "        elif len(nic_date_result.year) == 4:\n",
    "            year_number = np.uint16(nic_date_result.year)\n",
    "        else:\n",
    "            raise ValueError(\"Incorrect Year Parsed\")\n",
    "\n",
    "        return year_number\n",
    "\n",
    "    def convert_to_python_datetime(self):\n",
    "        python_date_time = datetime.datetime(year=self.year, month=self.month, day=self.day)\n",
    "        return python_date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from functools import lru_cache\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class NicDate(dict):\n",
    "    \"\"\"\n",
    "    The NicDate Class inputs the string values from regex search for month, day and year.\n",
    "    It inherits from dictionary.\n",
    "    A dataclass is used instead of a raw dictionary, because a dictionary is not hashable, and can not be cached by\n",
    "    @lru_cache. This class is  hashable and able to be reused in @lru_cache functions.\n",
    "\n",
    "    :raises: Value Error if verify_not_none method is called and\n",
    "    \"\"\"\n",
    "\n",
    "    def __hash__(self):\n",
    "        # Define a specific has for this class, so it can be cached.\n",
    "        hash_seed = hash(f\"{self.month}/{self.date}/{self.year}\")\n",
    "        return hash_seed\n",
    "\n",
    "    def __init__(self, month: str = str(), date: str = str(), year: str = ()):\n",
    "        super().__init__()\n",
    "        self.month = month\n",
    "        self.date = date\n",
    "        self.year = year\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Day = {self.date} Month = {self.month} Year = {self.year}\"\n",
    "\n",
    "    def verify_not_none(self):\n",
    "        \"\"\"\n",
    "        This function returns an error when called if any of the components are none.\n",
    "\n",
    "        :raises ValueError if any of the components are None.\n",
    "        \"\"\"\n",
    "        if any((self.month is None, self.date is None, self.year is None)):\n",
    "            raise ValueError(\"None Value passed\")\n",
    "\n",
    "    @staticmethod\n",
    "    @lru_cache(maxsize=12)\n",
    "    def find_largest_day(result_month: int = 0) -> dict:\n",
    "        months_numerical = np.arange(start=1, stop=13).astype(np.uint8)\n",
    "        month_max_days = np.array((31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31)).astype(np.uint8)\n",
    "        largest_day_dict = {a: b for a, b in zip(months_numerical, month_max_days)}\n",
    "        largest_day = largest_day_dict.get(result_month, np.nan)\n",
    "        return largest_day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "def date_sorter():\n",
    "    \n",
    "     # ~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    # read in the source file\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    doc = []\n",
    "    with open(r'.\\dates.txt') as file:\n",
    "        for line in file:\n",
    "            doc.append(line)\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    # Run the primary class and create a tuple where the first number is sequential and the 2nd number is text\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    pre_sorted_results = []\n",
    "    for line_counter, line_text in enumerate(doc):\n",
    "        try:\n",
    "            pre_sorted_results.append((line_counter, DateFinder(raw_string=line_text).convert_to_python_datetime()))\n",
    "        except ValueError as uhoh:\n",
    "            print(f\"{uhoh}\")\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    # sort on the date to get the value\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    sorted_results = copy.deepcopy(pre_sorted_results)\n",
    "    sorted_results.sort(key=lambda x: x[1])\n",
    "    final_results = [x[0] for x in sorted_results]\n",
    "\n",
    "\n",
    "    return final_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "date_sorter()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 85,\n",
       " 3,\n",
       " 54,\n",
       " 29,\n",
       " 154,\n",
       " 475,\n",
       " 14,\n",
       " 130,\n",
       " 99,\n",
       " 112,\n",
       " 226,\n",
       " 32,\n",
       " 172,\n",
       " 192,\n",
       " 487,\n",
       " 336,\n",
       " 416,\n",
       " 37,\n",
       " 324,\n",
       " 406,\n",
       " 423,\n",
       " 376,\n",
       " 381,\n",
       " 346,\n",
       " 58,\n",
       " 482,\n",
       " 437,\n",
       " 105,\n",
       " 155,\n",
       " 163,\n",
       " 300,\n",
       " 403,\n",
       " 96,\n",
       " 74,\n",
       " 157,\n",
       " 109,\n",
       " 183,\n",
       " 333,\n",
       " 83,\n",
       " 352,\n",
       " 279,\n",
       " 215,\n",
       " 156,\n",
       " 224,\n",
       " 474,\n",
       " 50,\n",
       " 318,\n",
       " 12,\n",
       " 320,\n",
       " 41,\n",
       " 166,\n",
       " 419,\n",
       " 371,\n",
       " 383,\n",
       " 4,\n",
       " 51,\n",
       " 364,\n",
       " 220,\n",
       " 466,\n",
       " 238,\n",
       " 24,\n",
       " 343,\n",
       " 205,\n",
       " 259,\n",
       " 316,\n",
       " 28,\n",
       " 94,\n",
       " 18,\n",
       " 304,\n",
       " 489,\n",
       " 284,\n",
       " 396,\n",
       " 310,\n",
       " 420,\n",
       " 124,\n",
       " 20,\n",
       " 118,\n",
       " 233,\n",
       " 73,\n",
       " 190,\n",
       " 319,\n",
       " 370,\n",
       " 494,\n",
       " 149,\n",
       " 240,\n",
       " 106,\n",
       " 337,\n",
       " 7,\n",
       " 201,\n",
       " 82,\n",
       " 66,\n",
       " 165,\n",
       " 435,\n",
       " 314,\n",
       " 379,\n",
       " 496,\n",
       " 425,\n",
       " 399,\n",
       " 6,\n",
       " 255,\n",
       " 297,\n",
       " 76,\n",
       " 168,\n",
       " 22,\n",
       " 260,\n",
       " 500,\n",
       " 151,\n",
       " 348,\n",
       " 79,\n",
       " 341,\n",
       " 442,\n",
       " 268,\n",
       " 362,\n",
       " 222,\n",
       " 135,\n",
       " 467,\n",
       " 40,\n",
       " 198,\n",
       " 356,\n",
       " 431,\n",
       " 81,\n",
       " 247,\n",
       " 445,\n",
       " 86,\n",
       " 216,\n",
       " 264,\n",
       " 75,\n",
       " 404,\n",
       " 459,\n",
       " 17,\n",
       " 26,\n",
       " 128,\n",
       " 455,\n",
       " 71,\n",
       " 45,\n",
       " 60,\n",
       " 104,\n",
       " 113,\n",
       " 430,\n",
       " 180,\n",
       " 89,\n",
       " 359,\n",
       " 471,\n",
       " 206,\n",
       " 138,\n",
       " 295,\n",
       " 398,\n",
       " 296,\n",
       " 36,\n",
       " 439,\n",
       " 248,\n",
       " 210,\n",
       " 62,\n",
       " 108,\n",
       " 286,\n",
       " 176,\n",
       " 100,\n",
       " 456,\n",
       " 25,\n",
       " 276,\n",
       " 422,\n",
       " 49,\n",
       " 427,\n",
       " 490,\n",
       " 137,\n",
       " 31,\n",
       " 275,\n",
       " 11,\n",
       " 179,\n",
       " 2,\n",
       " 281,\n",
       " 448,\n",
       " 186,\n",
       " 229,\n",
       " 136,\n",
       " 70,\n",
       " 493,\n",
       " 200,\n",
       " 353,\n",
       " 9,\n",
       " 277,\n",
       " 231,\n",
       " 335,\n",
       " 97,\n",
       " 39,\n",
       " 369,\n",
       " 169,\n",
       " 262,\n",
       " 405,\n",
       " 30,\n",
       " 438,\n",
       " 424,\n",
       " 55,\n",
       " 285,\n",
       " 486,\n",
       " 69,\n",
       " 33,\n",
       " 350,\n",
       " 42,\n",
       " 64,\n",
       " 417,\n",
       " 131,\n",
       " 56,\n",
       " 117,\n",
       " 77,\n",
       " 463,\n",
       " 331,\n",
       " 38,\n",
       " 257,\n",
       " 391,\n",
       " 217,\n",
       " 175,\n",
       " 181,\n",
       " 477,\n",
       " 313,\n",
       " 266,\n",
       " 116,\n",
       " 72,\n",
       " 219,\n",
       " 203,\n",
       " 441,\n",
       " 386,\n",
       " 374,\n",
       " 211,\n",
       " 90,\n",
       " 150,\n",
       " 27,\n",
       " 8,\n",
       " 436,\n",
       " 178,\n",
       " 483,\n",
       " 158,\n",
       " 413,\n",
       " 23,\n",
       " 195,\n",
       " 15,\n",
       " 152,\n",
       " 234,\n",
       " 207,\n",
       " 246,\n",
       " 123,\n",
       " 95,\n",
       " 227,\n",
       " 462,\n",
       " 98,\n",
       " 92,\n",
       " 52,\n",
       " 34,\n",
       " 454,\n",
       " 68,\n",
       " 47,\n",
       " 323,\n",
       " 67,\n",
       " 400,\n",
       " 488,\n",
       " 139,\n",
       " 63,\n",
       " 212,\n",
       " 53,\n",
       " 270,\n",
       " 120,\n",
       " 101,\n",
       " 443,\n",
       " 144,\n",
       " 311,\n",
       " 302,\n",
       " 114,\n",
       " 299,\n",
       " 479,\n",
       " 355,\n",
       " 1,\n",
       " 250,\n",
       " 193,\n",
       " 87,\n",
       " 173,\n",
       " 358,\n",
       " 332,\n",
       " 164,\n",
       " 301,\n",
       " 451,\n",
       " 478,\n",
       " 309,\n",
       " 197,\n",
       " 134,\n",
       " 48,\n",
       " 360,\n",
       " 65,\n",
       " 43,\n",
       " 410,\n",
       " 407,\n",
       " 194,\n",
       " 239,\n",
       " 484,\n",
       " 141,\n",
       " 312,\n",
       " 389,\n",
       " 57,\n",
       " 237,\n",
       " 373,\n",
       " 111,\n",
       " 249,\n",
       " 61,\n",
       " 182,\n",
       " 204,\n",
       " 170,\n",
       " 327,\n",
       " 91,\n",
       " 293,\n",
       " 143,\n",
       " 480,\n",
       " 5,\n",
       " 125,\n",
       " 132,\n",
       " 325,\n",
       " 122,\n",
       " 167,\n",
       " 469,\n",
       " 366,\n",
       " 214,\n",
       " 88,\n",
       " 354,\n",
       " 102,\n",
       " 334,\n",
       " 115,\n",
       " 460,\n",
       " 46,\n",
       " 339,\n",
       " 19,\n",
       " 223,\n",
       " 344,\n",
       " 21,\n",
       " 225,\n",
       " 13,\n",
       " 80,\n",
       " 388,\n",
       " 252,\n",
       " 121,\n",
       " 472,\n",
       " 78,\n",
       " 377,\n",
       " 328,\n",
       " 433,\n",
       " 385,\n",
       " 322,\n",
       " 213,\n",
       " 408,\n",
       " 267,\n",
       " 146,\n",
       " 202,\n",
       " 273,\n",
       " 457,\n",
       " 261,\n",
       " 306,\n",
       " 330,\n",
       " 421,\n",
       " 393,\n",
       " 159,\n",
       " 191,\n",
       " 418,\n",
       " 444,\n",
       " 84,\n",
       " 375,\n",
       " 126,\n",
       " 458,\n",
       " 148,\n",
       " 160,\n",
       " 329,\n",
       " 196,\n",
       " 378,\n",
       " 368,\n",
       " 395,\n",
       " 495,\n",
       " 305,\n",
       " 447,\n",
       " 44,\n",
       " 129,\n",
       " 263,\n",
       " 103,\n",
       " 450,\n",
       " 185,\n",
       " 470,\n",
       " 453,\n",
       " 235,\n",
       " 363,\n",
       " 357,\n",
       " 145,\n",
       " 292,\n",
       " 485,\n",
       " 189,\n",
       " 415,\n",
       " 93,\n",
       " 242,\n",
       " 307,\n",
       " 351,\n",
       " 426,\n",
       " 282,\n",
       " 208,\n",
       " 127,\n",
       " 147,\n",
       " 303,\n",
       " 452,\n",
       " 499,\n",
       " 340,\n",
       " 251,\n",
       " 345,\n",
       " 347,\n",
       " 349,\n",
       " 497,\n",
       " 107,\n",
       " 119,\n",
       " 271,\n",
       " 434,\n",
       " 308,\n",
       " 174,\n",
       " 253,\n",
       " 315,\n",
       " 411,\n",
       " 491,\n",
       " 278,\n",
       " 392,\n",
       " 265,\n",
       " 326,\n",
       " 290,\n",
       " 161,\n",
       " 133,\n",
       " 342,\n",
       " 338,\n",
       " 429,\n",
       " 188,\n",
       " 446,\n",
       " 498,\n",
       " 184,\n",
       " 272,\n",
       " 397,\n",
       " 294,\n",
       " 401,\n",
       " 361,\n",
       " 298,\n",
       " 372,\n",
       " 492,\n",
       " 390,\n",
       " 387,\n",
       " 289,\n",
       " 380,\n",
       " 269,\n",
       " 0,\n",
       " 473,\n",
       " 274,\n",
       " 288,\n",
       " 177,\n",
       " 449,\n",
       " 412,\n",
       " 409,\n",
       " 243,\n",
       " 365,\n",
       " 59,\n",
       " 171,\n",
       " 468,\n",
       " 16,\n",
       " 241,\n",
       " 317,\n",
       " 230,\n",
       " 218,\n",
       " 110,\n",
       " 228,\n",
       " 291,\n",
       " 461,\n",
       " 394,\n",
       " 283,\n",
       " 35,\n",
       " 221,\n",
       " 209,\n",
       " 244,\n",
       " 140,\n",
       " 321,\n",
       " 384,\n",
       " 245,\n",
       " 287,\n",
       " 481,\n",
       " 432,\n",
       " 280,\n",
       " 199,\n",
       " 382,\n",
       " 464,\n",
       " 367,\n",
       " 256,\n",
       " 440,\n",
       " 402,\n",
       " 476,\n",
       " 153,\n",
       " 258,\n",
       " 236,\n",
       " 465,\n",
       " 254,\n",
       " 142,\n",
       " 232,\n",
       " 428,\n",
       " 162,\n",
       " 187,\n",
       " 414]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_sorter()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "LvcWI",
   "launcher_item_id": "krne9",
   "part_id": "Mkp1I"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}